channel 1
event covid
flow_type inflow
flow_path ../data/inflow_hour20180101_20210228.npy
adj_path ../data/adjacency_matrix.npy
twitter_path ../data/Japan_COVID-19_Total_tweet_count.csv
pref_path ../data/Japan_prefectures.csv
freq 1H
flow_start_date 2018-01-01 00:00:00
flow_end_date 2021-02-28 23:59:59
twitter_start_date 2019-12-31 09:00:00
twitter_end_date 2021-02-28 08:00:00
target_start_date 2020-01-01 00:00:00
target_end_date 2020-12-31 23:00:00
target_area ['Hokkaido', 'Aomori', 'Iwate', 'Miyagi', 'Akita', 'Yamagata', 'Fukushima', 'Ibaraki', 'Tochigi', 'Gunma', 'Saitama', 'Chiba', 'Tokyo', 'Kanagawa', 'Niigata', 'Toyama', 'Ishikawa', 'Fukui', 'Yamanashi', 'Nagano', 'Gifu', 'Shizuoka', 'Aichi', 'Mie', 'Shiga', 'Kyoto', 'Osaka', 'Hyogo', 'Nara', 'Wakayama', 'Tottori', 'Shimane', 'Okayama', 'Hiroshima', 'Yamaguchi', 'Tokushima', 'Kagawa', 'Ehime', 'Kochi', 'Fukuoka', 'Saga', 'Nagasaki', 'Kumamoto', 'Oita', 'Miyazaki', 'Kagoshima', 'Okinawa']
model_name TransformerT
flow.shape, twitter.shape (8784, 47) -1.4002734875242022 3.5033527495834607 (8784, 47) -1.0 1.0
covid-inflow training started Sun Oct 17 18:19:35 2021
TRAIN XS.shape YS,shape (7008, 12, 47, 2) (7008, 12, 47, 1)
Model Training Started ... Sun Oct 17 18:19:35 2021
TIMESTEP_IN, TIMESTEP_OUT 12 12
XS_torch.shape:   torch.Size([7008, 12, 47, 2])
YS_torch.shape:   torch.Size([7008, 12, 47, 1])
epoch 0 time used: 2  seconds  train loss: 0.4225906093733859 validation loss: 0.23629875841750403
epoch 1 time used: 1  seconds  train loss: 0.24536255135837393 validation loss: 0.18307167829171708
epoch 2 time used: 1  seconds  train loss: 0.2112318799920278 validation loss: 0.16527748257602187
epoch 3 time used: 1  seconds  train loss: 0.19373087848067466 validation loss: 0.16174489967354902
epoch 4 time used: 1  seconds  train loss: 0.18515507695428132 validation loss: 0.14552398400219607
epoch 5 time used: 1  seconds  train loss: 0.1774617345320398 validation loss: 0.14937976601461297
epoch 6 time used: 1  seconds  train loss: 0.17682981334592654 validation loss: 0.14095906144407785
epoch 7 time used: 1  seconds  train loss: 0.17058749047860708 validation loss: 0.15677923889464984
epoch 8 time used: 1  seconds  train loss: 0.17081636079279436 validation loss: 0.14831500000333134
epoch 9 time used: 1  seconds  train loss: 0.16504102473571058 validation loss: 0.13991233345852594
epoch 10 time used: 1  seconds  train loss: 0.16379073096646202 validation loss: 0.14354586288264898
epoch 11 time used: 1  seconds  train loss: 0.15864090047651955 validation loss: 0.13830090848278237
epoch 12 time used: 1  seconds  train loss: 0.15753816601166806 validation loss: 0.14792926248894434
epoch 13 time used: 1  seconds  train loss: 0.15761866029266897 validation loss: 0.14313749336216547
epoch 14 time used: 1  seconds  train loss: 0.155588726837704 validation loss: 0.13821652157393766
epoch 15 time used: 1  seconds  train loss: 0.15287218820105222 validation loss: 0.1302167711328698
epoch 16 time used: 1  seconds  train loss: 0.1508589315496079 validation loss: 0.12662576907845938
epoch 17 time used: 1  seconds  train loss: 0.14806007867171522 validation loss: 0.13448189069691313
epoch 18 time used: 1  seconds  train loss: 0.15138852507828576 validation loss: 0.14427387367372643
epoch 19 time used: 1  seconds  train loss: 0.14816992794542008 validation loss: 0.12710673293974845
epoch 20 time used: 1  seconds  train loss: 0.14452667071666891 validation loss: 0.13302996060619615
epoch 21 time used: 1  seconds  train loss: 0.1447337450774293 validation loss: 0.12140003595177985
epoch 22 time used: 1  seconds  train loss: 0.14429104804448342 validation loss: 0.12967777871377936
epoch 23 time used: 1  seconds  train loss: 0.14530036109676825 validation loss: 0.13151560118209282
epoch 24 time used: 1  seconds  train loss: 0.14260934726469773 validation loss: 0.12679665164860415
epoch 25 time used: 1  seconds  train loss: 0.14107140948601873 validation loss: 0.11911612514355412
epoch 26 time used: 1  seconds  train loss: 0.14174816751770414 validation loss: 0.13707157023693328
epoch 27 time used: 1  seconds  train loss: 0.13999434520846268 validation loss: 0.132397705629536
epoch 28 time used: 1  seconds  train loss: 0.14146190746779494 validation loss: 0.12248369595503698
epoch 29 time used: 1  seconds  train loss: 0.13747838169018792 validation loss: 0.14739666035458376
epoch 30 time used: 1  seconds  train loss: 0.14284756550596547 validation loss: 0.13330060638249192
epoch 31 time used: 1  seconds  train loss: 0.13887648910420125 validation loss: 0.11538258126881569
epoch 32 time used: 1  seconds  train loss: 0.13928284077611688 validation loss: 0.12815300977393373
epoch 33 time used: 1  seconds  train loss: 0.1373023445203424 validation loss: 0.11410235525130137
epoch 34 time used: 1  seconds  train loss: 0.13591926260263046 validation loss: 0.12263410926273424
epoch 35 time used: 1  seconds  train loss: 0.13608130738932975 validation loss: 0.1165108747406093
epoch 36 time used: 1  seconds  train loss: 0.1324262762133208 validation loss: 0.1447296451488042
epoch 37 time used: 1  seconds  train loss: 0.1381794341600286 validation loss: 0.11812237714795762
epoch 38 time used: 1  seconds  train loss: 0.13372423087035504 validation loss: 0.1162852035265535
epoch 39 time used: 1  seconds  train loss: 0.13138086975890934 validation loss: 0.1353146454242811
epoch 40 time used: 1  seconds  train loss: 0.13282326390028362 validation loss: 0.11706301648186766
epoch 41 time used: 1  seconds  train loss: 0.13114961514552798 validation loss: 0.11000963814182368
epoch 42 time used: 1  seconds  train loss: 0.1318742769970197 validation loss: 0.11050925900538762
epoch 43 time used: 1  seconds  train loss: 0.12953367981282907 validation loss: 0.11864123809827518
epoch 44 time used: 1  seconds  train loss: 0.1303047693279236 validation loss: 0.1136594362318788
epoch 45 time used: 1  seconds  train loss: 0.12964922036618404 validation loss: 0.12552178314287368
epoch 46 time used: 1  seconds  train loss: 0.13160628739239782 validation loss: 0.11207745428362938
epoch 47 time used: 1  seconds  train loss: 0.12954858067917496 validation loss: 0.12669762254577793
epoch 48 time used: 1  seconds  train loss: 0.12994096945273823 validation loss: 0.11061507422630101
epoch 49 time used: 1  seconds  train loss: 0.1290074814354811 validation loss: 0.11341820994060334
epoch 50 time used: 1  seconds  train loss: 0.12771770065505755 validation loss: 0.11986939132757927
Early stopping at epoch: 51 
YS.shape, YS_pred.shape, (7008, 12, 47, 1) (7008, 12, 47, 1)
YS.shape, YS_pred.shape, (7008, 12, 47) (7008, 12, 47)
**************************************** 
TransformerT, train, Torch MSE, 1.2648933049e-01, 0.1264893305 
TransformerT, train, MSE, RMSE, MAE, MAPE, 4997107.6088267183, 2235.4211256107, 745.3847455239, 11.6291073806 
Model Training Ended ... Sun Oct 17 18:20:53 2021
covid-inflow testing started Sun Oct 17 18:20:53 2021
TEST XS.shape, YS.shape (1753, 12, 47, 2) (1753, 12, 47, 1)
Model Testing Started ... Sun Oct 17 18:20:53 2021
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1753, 12, 47, 1) (1753, 12, 47, 1)
YS.shape, YS_pred.shape, (1753, 12, 47) (1753, 12, 47)
**************************************** 
TransformerT, test, Torch MSE, 1.1854826978e-01, 0.1185482698 
all pred steps, TransformerT, test, MSE, RMSE, MAE, MAPE, 3380977.6231983574, 1838.7434903211, 669.8532677934, 11.6456704466 
1 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 530777.0462302694, 728.5444710038, 341.7076811010, 7.2762970406 
2 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 1830663.4510307184, 1353.0201221825, 549.5670649941, 9.6407462068 
3 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 3291064.3008028283, 1814.1290750117, 669.8750262524, 14.5716777859 
4 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 4248292.0146196876, 2061.1385238794, 712.9198781807, 11.0096338362 
5 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 4089897.0665762471, 2022.3493928044, 741.6520705499, 12.8035253049 
6 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 3948051.1763077728, 1986.9703511396, 743.2138330847, 13.3728904255 
7 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 3838773.0863658157, 1959.2787158457, 730.8577536607, 12.1031225051 
8 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 4135061.2903371886, 2033.4850110923, 726.6789852428, 12.3761866640 
9 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 4304474.2208619881, 2074.7226852912, 762.7212663972, 12.1610728844 
10 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 3830623.6505354489, 1957.1979078610, 709.2065301709, 12.0860438275 
11 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 3464615.6483747950, 1861.3478042469, 679.4631016876, 11.3504924735 
12 step, TransformerT, test, MSE, RMSE, MAE, MAPE, 3059438.5263375049, 1749.1250745265, 670.3760221983, 10.9963564053 
Model Testing Ended ... Sun Oct 17 18:20:54 2021
